{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch import from_numpy\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=torchvision.transforms.Compose([            \n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "class dem_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,DF):\n",
    "\n",
    "        \"\"\"\n",
    "        Las entradas de la red neuronal son\n",
    "        x: coordenada espacial x\n",
    "        y: coordenada espacial y\n",
    "        Profundidad: coordenada espacial z\n",
    "        DEM: path del dem\n",
    "        Pendite: path de la pendiente    \n",
    "\n",
    "        encode_class: Clase codificada   \n",
    "        \n",
    "        \"\"\"\n",
    "        self.x=DF[['x', 'y', 'Profundidad','DEM', 'Pendiente']]\n",
    "        self.y=from_numpy(np.vstack(DF['encode_class'].values))\n",
    "        \n",
    "        self.n_samples=self.x.shape[0]\n",
    "\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        dem = Image.open(self.x[\"DEM\"].iloc[index])\n",
    "        dem = transform(dem)\n",
    "        \n",
    "        pendiente = Image.open(self.x[\"Pendiente\"].iloc[index])\n",
    "        pendiente = transform(pendiente)        \n",
    "        \n",
    "\n",
    "        corrs = self.x[['x', 'y', 'Profundidad']].iloc[index].values\n",
    "        \n",
    "        coordenadas = torch.from_numpy(corrs)\n",
    "\n",
    "        coordenadas[-1] = coordenadas[-1]*10\n",
    "\n",
    "        # positional_encode es una instancia de la clase positional_3D_encode\n",
    "        coordenadas = positional_encode(coordenadas)\n",
    "        \n",
    "        target = self.y[index]\n",
    "        \n",
    "        return torch.cat([dem.float(),pendiente.float()],0),coordenadas.float(),target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return  self.n_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelado_3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe287652dc7712a7671ec229ee9c548b969d03754bd579f8a7fc20061e2d7c34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
